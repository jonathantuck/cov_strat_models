{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import strat_models\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def joint_cov_prox(Y, nu, theta, t):\n",
    "    \"\"\"\n",
    "    Proximal operator for joint covariance estimation\n",
    "    \"\"\"\n",
    "    if Y is None:\n",
    "        return nu\n",
    "\n",
    "    n, nk = Y[0].shape\n",
    "    Yemp = Y[0]@Y[0].T\n",
    "    \n",
    "    s, Q = np.linalg.eigh(nu/(t*nk)-Yemp/nk)\n",
    "    w = ((t*nk)*s + np.sqrt(((t*nk)*s)**2 + 4*(t*nk)))/2\n",
    "    return Q @ np.diag(w) @ Q.T\n",
    "\n",
    "class covariance_max_likelihood_loss(strat_models.Loss):\n",
    "    \"\"\"\n",
    "    f(theta) = Trace(theta @ Y) - logdet(theta)\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.isDistribution = True\n",
    "\n",
    "    def evaluate(self, theta, data):\n",
    "        assert \"Y\" in data\n",
    "        return np.trace(theta @ data[\"Y\"]) - np.linalg.slogdet(theta)[1]\n",
    "\n",
    "    def setup(self, data, G):\n",
    "        Y = data[\"Y\"]\n",
    "        Z = data[\"Z\"]\n",
    "\n",
    "        K = len(G.nodes())\n",
    "\n",
    "        shape = (data[\"n\"], data[\"n\"])\n",
    "        theta_shape = (K,) + shape\n",
    "\n",
    "        #preprocess data\n",
    "        for y, z in zip(Y, Z):\n",
    "            vertex = G._node[z]\n",
    "            if \"Y\" in vertex:\n",
    "                vertex[\"Y\"] += [y]\n",
    "            else:\n",
    "                vertex[\"Y\"] = [y]\n",
    "\n",
    "        Y_data = []\n",
    "        for i, node in enumerate(G.nodes()):\n",
    "            vertex = G._node[node]\n",
    "            if 'Y' in vertex:\n",
    "                Y = vertex['Y']\n",
    "                Y_data += [Y]\n",
    "                del vertex['Y']\n",
    "            else:\n",
    "                Y_data += [None]\n",
    "\n",
    "        cache = {\"Y\": Y_data, \"n\":data[\"n\"], \"theta_shape\":theta_shape, \"shape\":shape, \"K\":K}\n",
    "        return cache\n",
    "\n",
    "    def prox(self, t, nu, warm_start, pool, cache):\n",
    "        \"\"\"\n",
    "        Proximal operator for joint covariance estimation\n",
    "        \"\"\"\n",
    "        res = pool.starmap(joint_cov_prox, zip(cache[\"Y\"], nu, warm_start, t*np.ones(cache[\"K\"])))\n",
    "        return np.array(res)\n",
    "\n",
    "    def logprob(self, data, G):\n",
    "        \n",
    "        logprobs = []\n",
    "        \n",
    "        for y,z in zip(data[\"Y\"], data[\"Z\"]):\n",
    "            n, nk = y.shape\n",
    "            \n",
    "            Y = (y@y.T)/nk\n",
    "            \n",
    "            if (np.zeros((n,n)) == Y).all():\n",
    "#                 logprobs += [0]\n",
    "                continue            \n",
    "            \n",
    "            theta = G._node[z][\"theta\"]\n",
    "            logprobs += [np.linalg.slogdet(theta)[1] - np.trace(Y@theta)]\n",
    "\n",
    "        return logprobs\n",
    "\n",
    "    def sample(self, data, G):\n",
    "        Z = turn_into_iterable(data[\"Z\"])\n",
    "        sigmas = [np.linalg.inv(G._node[z][\"theta\"]) for z in Z]\n",
    "\n",
    "        n = sigmas[0].shape[0]\n",
    "        return [np.random.multivariate_normal(np.zeros(n), sigma) for sigma in sigmas]\n",
    "    \n",
    "class trace_offdiagL1Norm(strat_models.Regularizer):\n",
    "    \"\"\"\n",
    "    r(theta) = lambd_0 * Tr(theta) + lambd_1 * || theta ||_{off diagonal, 1}\n",
    "    \"\"\"\n",
    "    def __init__(self, lambd=(1,1)):\n",
    "#         super().__init__(lambd)\n",
    "        self.lambd = lambd\n",
    "    \n",
    "    def evaluate(self, theta):\n",
    "        od_idx = np.where(~np.eye(theta.shape[0],dtype=bool))\n",
    "        \n",
    "        return self.lambd[0]*np.trace(theta) + self.lambd[1]*np.norm(theta[od_idx], 1)\n",
    "    \n",
    "    def prox(self, t, nu, warm_start, pool):\n",
    "        if self.lambd == (0,0):\n",
    "            return nu\n",
    "        \n",
    "        K = nu.shape[0]\n",
    "        n = nu.shape[1]\n",
    "        \n",
    "        diag_idx = np.where(np.eye(n,dtype=bool))\n",
    "        od_idx = np.where(~np.eye(n,dtype=bool))\n",
    "        \n",
    "        T = np.zeros((K, n, n))\n",
    "\n",
    "        for k in range(K):\n",
    "            T[k][diag_idx] = nu[k][diag_idx] - self.lambd[0]*t\n",
    "            T[k][od_idx] = np.maximum(nu[k][od_idx] - self.lambd[1]*t, 0) - np.maximum(-nu[k][od_idx] - self.lambd[1]*t, 0)\n",
    "        \n",
    "        return T\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n = 30\n",
      "K_range = 10\n",
      "K_azimuth = 10\n",
      "K_doppler = 10\n",
      "K = 1000\n"
     ]
    }
   ],
   "source": [
    "n = 30\n",
    "K_range = 10\n",
    "K_azimuth = 10\n",
    "K_doppler = 10\n",
    "K = K_range * K_azimuth * K_doppler\n",
    "\n",
    "print(\"n = {}\".format(n))\n",
    "\n",
    "print(\"K_range = {}\".format(K_range))\n",
    "print(\"K_azimuth = {}\".format(K_azimuth))\n",
    "print(\"K_doppler = {}\".format(K_doppler))\n",
    "\n",
    "print(\"K = {}\".format(K_range * K_azimuth * K_doppler))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranges = [x for x in np.linspace(35e3, 50e3, K_range)] #meters\n",
    "azimuths = [x for x in np.linspace(87, 267, K_azimuth)] #Radians\n",
    "dopplers = [x for x in np.linspace(-992, 992, K_doppler)] #Hz\n",
    "\n",
    "dict_ranges = {}\n",
    "for k in range(K_range):\n",
    "    dict_ranges[k] = ranges[k]\n",
    "\n",
    "G_range = nx.relabel_nodes(nx.path_graph(K_range), dict_ranges)\n",
    "\n",
    "dict_azimuths = {}\n",
    "for k in range(K_azimuth):\n",
    "    dict_azimuths[k] = azimuths[k]\n",
    "    \n",
    "G_azimuth = nx.relabel_nodes(nx.cycle_graph(K_azimuth), dict_azimuths)\n",
    "\n",
    "dict_dopplers = {}\n",
    "for k in range(K_doppler):\n",
    "    dict_dopplers[k] = dopplers[k]\n",
    "\n",
    "G_doppler = nx.relabel_nodes(nx.path_graph(K_doppler), dict_dopplers)\n",
    "\n",
    "G = strat_models.cartesian_product([G_range, G_azimuth, G_doppler])\n",
    "\n",
    "nodelist = G.nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6600"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L = nx.laplacian_matrix(G).A\n",
    "np.sum(L != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data_experiment_1():\n",
    "    Z = []\n",
    "    S_trues = dict()\n",
    "\n",
    "    Y_train, Y_test = [], []\n",
    "    \n",
    "    psd_doppler = np.random.randn(n,n)\n",
    "    psd_doppler = psd_doppler @ np.conj(psd_doppler).T / (n) + 2*np.random.rand(n)*np.eye(n)\n",
    "\n",
    "    psd_azimuth = 2*np.random.randn(n,n)\n",
    "    psd_azimuth = psd_azimuth @ np.conj(psd_azimuth).T / (n) + np.random.rand(n)*np.eye(n)\n",
    "\n",
    "    psd_range = np.random.randn(n,n)\n",
    "    psd_range = psd_range @ np.conj(psd_range).T / (n) + 2*np.random.rand(n)*np.eye(n)\n",
    "\n",
    "    NUM_SAMPLES_TRAIN = []\n",
    "    NUM_SAMPLES_TEST = []\n",
    "    \n",
    "    for node in G.nodes():\n",
    "        RANGE, AZIMUTH, DOPPLER = node\n",
    "\n",
    "        S_true = (1+DOPPLER/1000)*psd_doppler\n",
    "        S_true += (np.cos(np.pi*AZIMUTH/180)+np.sin(np.pi*AZIMUTH/180))*psd_azimuth\n",
    "        S_true += ((4e4 / RANGE)**2)*psd_range\n",
    "        \n",
    "        S_trues[node] = S_true\n",
    "\n",
    "        num_samples_node_train = np.random.choice(list(range(n//(3))) + [0]*(n) + [1]*(n//3) + [n])\n",
    "        num_samples_node_test = np.random.choice(list(range(1, n//11+1)) + [n] + [1]*300 + [2]*10)\n",
    "        \n",
    "        NUM_SAMPLES_TRAIN += [num_samples_node_train]\n",
    "        NUM_SAMPLES_TEST += [num_samples_node_test]\n",
    "\n",
    "        y_train = np.random.multivariate_normal(np.zeros(n), np.real(S_true), num_samples_node_train).T\n",
    "        y_test = np.random.multivariate_normal(np.zeros(n), np.real(S_true), num_samples_node_test).T\n",
    "        \n",
    "        if num_samples_node_train == 0:\n",
    "            y_train = np.zeros((n,1))\n",
    "\n",
    "        Z += [node]\n",
    "\n",
    "        Y_train += [y_train]\n",
    "        Y_test += [y_test]\n",
    "\n",
    "    data_train = dict(Y=Y_train, Z=Z, n=n)\n",
    "    data_test = dict(Y=Y_test, Z=Z, n=n)\n",
    "    \n",
    "    #for common\n",
    "    data_train_common = dict(Y=Y_train, Z=[0]*len(Y_train), n=n)\n",
    "    data_test_common = dict(Y=Y_test, Z=[0]*len(Y_test), n=n)\n",
    "    \n",
    "    return data_train, data_test, data_train_common, data_test_common, S_trues, NUM_SAMPLES_TRAIN, NUM_SAMPLES_TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathantuck/opt/anaconda3/envs/research/lib/python3.6/site-packages/ipykernel_launcher.py:34: RuntimeWarning: covariance is not positive-semidefinite.\n",
      "/Users/jonathantuck/opt/anaconda3/envs/research/lib/python3.6/site-packages/ipykernel_launcher.py:35: RuntimeWarning: covariance is not positive-semidefinite.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"EXPERIMENT 1\"\"\"\n",
    "\n",
    "data_train, data_test, data_train_common, data_test_common, S_trues, NUM_SAMPLES_TRAIN, NUM_SAMPLES_TEST = generate_data_experiment_1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of vertices with no training samples: 625\n",
      "Max number of training samples per vertex: 30\n",
      "Mean number of training samples per vertex: 1.743\n"
     ]
    }
   ],
   "source": [
    "##Statistics about training samples\n",
    "\n",
    "print(\"Number of vertices with no training samples:\", sum(np.array(NUM_SAMPLES_TRAIN) == 0))\n",
    "print(\"Max number of training samples per vertex:\", max(NUM_SAMPLES_TRAIN))\n",
    "print(\"Mean number of training samples per vertex:\", np.mean(NUM_SAMPLES_TRAIN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Common model, local weights =  (0.001, 59.6)\n",
      " it |     s_norm     r_norm    eps_pri   eps_dual    rho  time1  time2  time3\n",
      "  1 | 3.8117e+00 3.8041e+00 8.0543e-03 8.0543e-03 1.000 12.777 0.240 84.969\n",
      "  2 | 6.7669e-01 3.7453e+00 7.9880e-03 8.2324e-03 1.000 7.231 0.105 72.499\n",
      "  3 | 1.2268e+00 2.8594e+00 7.1021e-03 7.8486e-03 1.000 6.455 0.093 99.680\n",
      "  4 | 1.2532e+00 2.1661e+00 6.4087e-03 8.1272e-03 1.000 5.308 0.079 102.334\n",
      "  5 | 1.2726e+00 1.7266e+00 5.9692e-03 8.9795e-03 1.000 5.136 0.084 98.706\n",
      "  6 | 1.3366e+00 1.4268e+00 5.6694e-03 1.0123e-02 1.000 5.892 0.087 99.336\n",
      "  7 | 1.3966e+00 1.2032e+00 5.6393e-03 1.1415e-02 1.000 5.362 0.084 98.650\n",
      "  8 | 1.4410e+00 1.0296e+00 5.6837e-03 1.2792e-02 1.000 6.640 0.087 95.379\n",
      "  9 | 1.4694e+00 8.9498e-01 5.7120e-03 1.4215e-02 1.000 4.823 0.081 96.389\n",
      " 10 | 1.4834e+00 7.9400e-01 5.7260e-03 1.5661e-02 1.000 4.913 0.085 94.984\n",
      " 11 | 1.4849e+00 7.2285e-01 5.7275e-03 1.7112e-02 1.000 4.943 0.081 97.536\n",
      " 12 | 1.4757e+00 6.7736e-01 5.7183e-03 1.8556e-02 1.000 5.624 0.076 105.755\n",
      " 13 | 1.4575e+00 6.5200e-01 5.7001e-03 1.9980e-02 1.000 4.686 0.081 97.329\n",
      " 14 | 1.4322e+00 6.4024e-01 5.6748e-03 2.1378e-02 1.000 4.645 0.078 101.926\n",
      " 15 | 1.4013e+00 6.3565e-01 5.6440e-03 2.2743e-02 1.000 4.944 0.086 96.477\n",
      " 16 | 1.3667e+00 6.3290e-01 5.6093e-03 2.4071e-02 1.000 4.632 0.079 96.691\n",
      " 17 | 1.3296e+00 6.2827e-01 5.5722e-03 2.5359e-02 1.000 5.680 0.086 95.271\n",
      " 18 | 1.2913e+00 6.1964e-01 5.5339e-03 2.6606e-02 1.000 4.772 0.081 97.171\n",
      " 19 | 1.2528e+00 6.0630e-01 5.4954e-03 2.7811e-02 1.000 4.705 0.081 96.048\n",
      " 20 | 1.2148e+00 5.8854e-01 5.4574e-03 2.8975e-02 1.000 6.093 0.088 95.994\n",
      " 21 | 1.1778e+00 5.6733e-01 5.4204e-03 3.0101e-02 1.000 4.380 0.077 97.283\n",
      " 22 | 1.1422e+00 5.4393e-01 5.3849e-03 3.1188e-02 1.000 5.189 0.085 95.625\n",
      " 23 | 1.1082e+00 5.1961e-01 5.3508e-03 3.2241e-02 1.000 4.943 0.197 99.458\n",
      " 24 | 1.0758e+00 4.9545e-01 5.3185e-03 3.3261e-02 1.000 6.028 0.083 104.383\n",
      " 25 | 1.0452e+00 4.7218e-01 5.2878e-03 3.4250e-02 1.000 5.699 0.084 97.999\n",
      " 26 | 1.0162e+00 4.5020e-01 5.2588e-03 3.5211e-02 1.000 4.673 0.081 95.262\n",
      " 27 | 9.8886e-01 4.2962e-01 5.2315e-03 3.6145e-02 1.000 6.702 0.103 95.508\n",
      " 28 | 9.6306e-01 4.1041e-01 5.2057e-03 3.7055e-02 1.000 4.770 0.079 94.122\n",
      " 29 | 9.3872e-01 3.9244e-01 5.1814e-03 3.7942e-02 1.000 4.730 0.078 95.351\n",
      " 30 | 9.1572e-01 3.7564e-01 5.1584e-03 3.8808e-02 1.000 6.268 0.104 96.643\n",
      " 31 | 8.9394e-01 3.5998e-01 5.1366e-03 3.9654e-02 1.000 6.351 0.081 105.577\n",
      " 32 | 8.7327e-01 3.4550e-01 5.1159e-03 4.0480e-02 1.000 5.778 0.077 100.628\n",
      " 33 | 8.5361e-01 3.3225e-01 5.0963e-03 4.1289e-02 1.000 5.797 0.084 95.669\n",
      " 34 | 8.3487e-01 3.2030e-01 5.0775e-03 4.2081e-02 1.000 4.816 0.076 96.557\n",
      " 35 | 8.1696e-01 3.0966e-01 5.0596e-03 4.2858e-02 1.000 5.754 0.084 96.043\n",
      " 36 | 7.9981e-01 3.0032e-01 5.0425e-03 4.3618e-02 1.000 4.409 0.074 95.705\n",
      " 37 | 7.8336e-01 2.9221e-01 5.0260e-03 4.4365e-02 1.000 5.890 0.084 94.842\n",
      " 38 | 7.6755e-01 2.8520e-01 5.0102e-03 4.5097e-02 1.000 5.251 0.070 95.760\n",
      " 39 | 7.5233e-01 2.7918e-01 4.9950e-03 4.5816e-02 1.000 5.045 0.082 96.066\n",
      " 40 | 7.3766e-01 2.7395e-01 4.9803e-03 4.6523e-02 1.000 5.192 0.089 95.981\n",
      " 41 | 7.2350e-01 2.6937e-01 4.9661e-03 4.7217e-02 1.000 4.701 0.082 96.859\n",
      " 42 | 7.0983e-01 2.6524e-01 4.9525e-03 4.7899e-02 1.000 4.929 0.078 96.061\n",
      " 43 | 6.9662e-01 2.6142e-01 4.9393e-03 4.8569e-02 1.000 6.188 0.083 97.768\n",
      " 44 | 6.8385e-01 2.5777e-01 4.9265e-03 4.9229e-02 1.000 6.383 0.094 100.557\n",
      " 45 | 6.7149e-01 2.5416e-01 4.9141e-03 4.9878e-02 1.000 4.450 0.077 97.772\n",
      " 46 | 6.5954e-01 2.5052e-01 4.9022e-03 5.0516e-02 1.000 6.130 0.086 101.141\n",
      " 47 | 6.4798e-01 2.4679e-01 4.8906e-03 5.1144e-02 1.000 4.472 0.080 102.097\n",
      " 48 | 6.3679e-01 2.4295e-01 4.8794e-03 5.1763e-02 1.000 5.009 0.083 98.013\n",
      " 49 | 6.2597e-01 2.3897e-01 4.8686e-03 5.2371e-02 1.000 6.328 0.085 96.086\n",
      " 50 | 6.1551e-01 2.3488e-01 4.8581e-03 5.2971e-02 1.000 4.773 0.077 96.488\n",
      " 51 | 6.0538e-01 2.3068e-01 4.8480e-03 5.3562e-02 1.000 5.362 0.084 95.592\n",
      " 52 | 5.9560e-01 2.2639e-01 4.8382e-03 5.4143e-02 1.000 5.398 0.084 96.794\n",
      " 53 | 5.8614e-01 2.2204e-01 4.8288e-03 5.4717e-02 1.000 4.882 0.092 98.262\n",
      " 54 | 5.7699e-01 2.1763e-01 4.8196e-03 5.5282e-02 1.000 4.627 0.081 104.991\n",
      " 55 | 5.6815e-01 2.1320e-01 4.8108e-03 5.5839e-02 1.000 5.732 0.089 99.308\n",
      " 56 | 5.5961e-01 2.0873e-01 4.8023e-03 5.6389e-02 1.000 4.710 0.080 103.219\n",
      " 57 | 5.5136e-01 2.0425e-01 4.7940e-03 5.6931e-02 1.000 5.482 0.079 97.400\n",
      " 58 | 5.4339e-01 1.9975e-01 4.7860e-03 5.7466e-02 1.000 4.503 0.079 95.568\n",
      " 59 | 5.3569e-01 1.9522e-01 4.7783e-03 5.7994e-02 1.000 5.961 0.082 96.333\n",
      " 60 | 5.2826e-01 1.9066e-01 4.7709e-03 5.8515e-02 1.000 4.575 0.077 96.582\n",
      " 61 | 5.2107e-01 1.8607e-01 4.7637e-03 5.9029e-02 1.000 5.714 0.079 96.403\n",
      " 62 | 5.1413e-01 1.8143e-01 4.7568e-03 5.9537e-02 1.000 4.568 0.079 101.747\n",
      " 63 | 5.0742e-01 1.7676e-01 4.7501e-03 6.0038e-02 1.000 5.697 0.081 97.530\n",
      " 64 | 5.0094e-01 1.7204e-01 4.7436e-03 6.0534e-02 1.000 4.956 0.088 97.736\n",
      " 65 | 4.9468e-01 1.6727e-01 4.7373e-03 6.1024e-02 1.000 4.663 0.075 95.882\n",
      " 66 | 4.8863e-01 1.6247e-01 4.7313e-03 6.1508e-02 1.000 5.119 0.076 96.517\n",
      " 67 | 4.8278e-01 1.5763e-01 4.7254e-03 6.1987e-02 1.000 4.466 0.076 97.490\n",
      " 68 | 4.7713e-01 1.5278e-01 4.7198e-03 6.2460e-02 1.000 4.585 0.077 98.735\n",
      " 69 | 4.7166e-01 1.4791e-01 4.7143e-03 6.2928e-02 1.000 5.051 0.084 98.119\n",
      " 70 | 4.6637e-01 1.4304e-01 4.7090e-03 6.3391e-02 1.000 5.645 0.074 102.200\n",
      " 71 | 4.6125e-01 1.3819e-01 4.7039e-03 6.3849e-02 1.000 5.496 0.081 95.827\n",
      " 72 | 4.5630e-01 1.3337e-01 4.6989e-03 6.4302e-02 1.000 4.267 0.078 96.083\n",
      " 73 | 4.5150e-01 1.2860e-01 4.6941e-03 6.4751e-02 1.000 5.861 0.087 99.856\n",
      " 74 | 4.4686e-01 1.2388e-01 4.6895e-03 6.5196e-02 1.000 4.443 0.080 103.203\n",
      " 75 | 4.4235e-01 1.1925e-01 4.6850e-03 6.5636e-02 1.000 4.638 0.080 101.980\n",
      " 76 | 4.3799e-01 1.1471e-01 4.6806e-03 6.6071e-02 1.000 4.638 0.083 96.257\n",
      " 77 | 4.3376e-01 1.1027e-01 4.6764e-03 6.6503e-02 1.000 6.155 0.088 98.474\n",
      " 78 | 4.2966e-01 1.0595e-01 4.6723e-03 6.6931e-02 1.000 5.682 0.080 98.012\n",
      " 79 | 4.2567e-01 1.0176e-01 4.6683e-03 6.7354e-02 1.000 4.703 0.111 97.068\n",
      " 80 | 4.2181e-01 9.7714e-02 4.6644e-03 6.7774e-02 1.000 4.715 0.085 99.174\n",
      " 81 | 4.1805e-01 9.3811e-02 4.6607e-03 6.8191e-02 1.000 4.620 0.072 96.557\n",
      " 82 | 4.1440e-01 9.0063e-02 4.6570e-03 6.8603e-02 1.000 5.329 0.083 95.885\n",
      " 83 | 4.1085e-01 8.6473e-02 4.6535e-03 6.9013e-02 1.000 4.890 0.080 95.544\n",
      " 84 | 4.0739e-01 8.3047e-02 4.6500e-03 6.9418e-02 1.000 6.123 0.153 103.590\n",
      " 85 | 4.0403e-01 7.9785e-02 4.6467e-03 6.9821e-02 1.000 6.961 0.084 96.080\n",
      " 86 | 4.0076e-01 7.6688e-02 4.6434e-03 7.0220e-02 1.000 4.286 0.079 96.571\n",
      " 87 | 3.9757e-01 7.3756e-02 4.6402e-03 7.0617e-02 1.000 5.435 0.086 95.223\n",
      " 88 | 3.9446e-01 7.0986e-02 4.6371e-03 7.1010e-02 1.000 5.659 0.081 96.977\n",
      " 89 | 3.9142e-01 6.8375e-02 4.6341e-03 7.1400e-02 1.000 4.419 0.080 95.982\n",
      " 90 | 3.8846e-01 6.5919e-02 4.6311e-03 7.1787e-02 1.000 4.960 0.083 95.999\n",
      " 91 | 3.8557e-01 6.3613e-02 4.6282e-03 7.2171e-02 1.000 4.811 0.084 98.394\n",
      " 92 | 3.8275e-01 6.1451e-02 4.6254e-03 7.2553e-02 1.000 6.427 0.083 99.023\n",
      " 93 | 3.7999e-01 5.9427e-02 4.6226e-03 7.2932e-02 1.000 5.800 0.084 97.189\n",
      " 94 | 3.7730e-01 5.7534e-02 4.6199e-03 7.3308e-02 1.000 4.708 0.081 99.591\n",
      " 95 | 3.7466e-01 5.5764e-02 4.6173e-03 7.3681e-02 1.000 5.067 0.084 102.460\n",
      " 96 | 3.7208e-01 5.4111e-02 4.6147e-03 7.4052e-02 1.000 5.128 0.120 98.084\n",
      " 97 | 3.6955e-01 5.2567e-02 4.6122e-03 7.4421e-02 1.000 5.081 0.090 102.588\n",
      " 98 | 3.6708e-01 5.1125e-02 4.6097e-03 7.4787e-02 1.000 4.687 0.079 98.939\n",
      " 99 | 3.6465e-01 4.9778e-02 4.6073e-03 7.5150e-02 1.000 4.986 0.086 96.360\n",
      "100 | 3.6228e-01 4.8518e-02 4.6049e-03 7.5511e-02 1.000 4.732 0.081 96.537\n",
      "Terminated (reached max iterations).\n",
      "run time: 1.0332e+01 seconds\n",
      "RESULTS OF COMMON MODEL:\n",
      "\t\t Info:  {'time': 10.331905874889344, 'iterations': 100, 'optimal': False}\n",
      "\t\t Test ANLL:  0.15340005581685387\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Common model\"\"\"\n",
    "min_anll = np.inf\n",
    "argmin_gamma = (np.inf, np.inf)\n",
    "weights = np.logspace(np.log10(1e-3), np.log10(1e3), 100)\n",
    "kwargs = dict(verbose=True, abs_tol=1e-4, maxiter=100)\n",
    "\n",
    "Y_train_common = []\n",
    "for (y,z) in zip(data_train[\"Y\"], data_train[\"Z\"]):\n",
    "    if abs(np.sum(y)) <= 1e-9:\n",
    "        continue\n",
    "    Y_train_common += [y]\n",
    "\n",
    "dict(Y=np.hstack(Y_train_common), Z=[0], n=n)    \n",
    "\n",
    "gamma = (0.001, 59.6)\n",
    "print(\"\\t Common model, local weights = \", gamma)\n",
    "\n",
    "G = nx.empty_graph(1)\n",
    "\n",
    "loss = covariance_max_likelihood_loss()\n",
    "reg = trace_offdiagL1Norm(lambd=gamma)\n",
    "\n",
    "bm = strat_models.BaseModel(loss=loss, reg=reg)\n",
    "common = strat_models.StratifiedModel(bm, graph=G)\n",
    "\n",
    "info = common.fit(data_train_common, **kwargs)\n",
    "\n",
    "anll = common.anll(data_test_common)/sum(NUM_SAMPLES_TEST)\n",
    "print(\"RESULTS OF COMMON MODEL:\")\n",
    "print(\"\\t\\t Info: \", info)\n",
    "print(\"\\t\\t Test ANLL: \", anll)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Stratified model, local weights =  (2.68, 0.66)\n",
      "\t (r,a,d) weights =  (10.52, 34.3, 86.97)\n",
      " it |     s_norm     r_norm    eps_pri   eps_dual    rho  time1  time2  time3\n",
      "  1 | 4.7731e+02 1.8875e+02 6.1147e-01 6.1147e-01 1.000 454.954 28.510 676.319\n",
      "  2 | 2.4873e+02 5.2961e+01 3.8289e-01 8.5987e-01 1.000 1109.179 29.883 734.407\n",
      "  3 | 9.6237e+01 1.3923e+02 2.7340e-01 9.5292e-01 1.000 1216.955 31.084 729.059\n",
      "  4 | 4.6851e+01 1.1349e+02 2.4765e-01 9.3859e-01 1.000 1100.005 29.772 713.582\n",
      "  5 | 7.2368e+01 4.7515e+01 2.0653e-01 8.9064e-01 1.000 757.034 33.760 737.574\n",
      "  6 | 5.6279e+01 5.1284e+00 1.9044e-01 8.6041e-01 1.000 1123.237 30.226 735.333\n",
      "  7 | 3.2199e+01 2.6693e+01 1.6636e-01 8.5276e-01 2.000 1245.251 30.134 727.978\n",
      "  8 | 2.4251e+01 3.1203e+01 1.6537e-01 8.7171e-01 2.000 1168.621 28.469 738.674\n",
      "  9 | 2.2460e+01 2.2112e+01 1.5662e-01 9.0159e-01 2.000 1266.852 30.553 744.555\n",
      " 10 | 2.1018e+01 1.1522e+01 1.5518e-01 9.3206e-01 2.000 1046.213 30.240 737.712\n",
      " 11 | 1.9383e+01 3.8263e+00 1.5355e-01 9.5936e-01 2.000 1138.741 28.527 733.488\n",
      " 12 | 1.8042e+01 6.3124e-01 1.5221e-01 9.8295e-01 2.000 1202.277 29.302 729.430\n",
      " 13 | 1.6458e+01 2.2921e+00 1.5062e-01 1.0227e+00 4.000 1304.499 29.359 729.676\n",
      " 14 | 1.5429e+01 1.9360e+00 1.4959e-01 1.0596e+00 4.000 1133.102 30.485 730.172\n",
      " 15 | 1.4653e+01 2.6408e+00 1.4882e-01 1.0954e+00 4.000 1131.009 28.823 732.326\n",
      " 16 | 1.4000e+01 4.0480e+00 1.4816e-01 1.1308e+00 4.000 1067.310 28.313 745.713\n",
      " 17 | 1.3411e+01 5.0989e+00 1.4757e-01 1.1660e+00 4.000 1145.528 28.638 728.474\n",
      " 18 | 1.2860e+01 5.7025e+00 1.4702e-01 1.2010e+00 4.000 1158.463 28.296 735.092\n",
      " 19 | 1.2338e+01 5.9456e+00 1.4650e-01 1.2356e+00 4.000 1114.316 28.421 732.312\n",
      " 20 | 1.1837e+01 5.9346e+00 1.4600e-01 1.2696e+00 4.000 1117.794 28.375 729.506\n",
      " 21 | 1.1361e+01 5.7628e+00 1.4553e-01 1.3029e+00 4.000 1190.209 30.657 731.164\n",
      " 22 | 1.0910e+01 5.4997e+00 1.4507e-01 1.3355e+00 4.000 1188.260 28.772 728.768\n",
      " 23 | 1.0481e+01 5.1971e+00 1.4465e-01 1.3673e+00 4.000 1177.871 28.413 730.673\n",
      " 24 | 1.0072e+01 4.8866e+00 1.4424e-01 1.3981e+00 4.000 1053.045 30.144 728.694\n",
      " 25 | 9.6828e+00 4.5860e+00 1.4385e-01 1.4281e+00 4.000 1167.133 30.385 732.314\n",
      " 26 | 9.3120e+00 4.3041e+00 1.4348e-01 1.4572e+00 4.000 1108.922 28.461 731.344\n",
      " 27 | 8.9576e+00 4.0438e+00 1.4312e-01 1.4853e+00 4.000 1164.566 28.609 726.925\n",
      " 28 | 8.6208e+00 3.8042e+00 1.4278e-01 1.5126e+00 4.000 1207.031 28.866 729.826\n",
      " 29 | 8.2985e+00 3.5841e+00 1.4246e-01 1.5390e+00 4.000 1089.446 30.209 732.162\n",
      " 30 | 7.9910e+00 3.3814e+00 1.4216e-01 1.5645e+00 4.000 1242.660 29.458 732.226\n",
      " 31 | 7.6981e+00 3.1930e+00 1.4186e-01 1.5892e+00 4.000 1108.442 29.189 729.154\n",
      " 32 | 7.4188e+00 3.0186e+00 1.4158e-01 1.6130e+00 4.000 1080.662 28.696 733.734\n",
      " 33 | 7.1528e+00 2.8563e+00 1.4132e-01 1.6361e+00 4.000 1058.658 28.291 729.164\n",
      " 34 | 6.8967e+00 2.7063e+00 1.4106e-01 1.6584e+00 4.000 1107.572 28.470 727.591\n",
      " 35 | 6.6525e+00 2.5665e+00 1.4082e-01 1.6799e+00 4.000 1178.711 28.675 726.894\n",
      " 36 | 6.4171e+00 2.4360e+00 1.4058e-01 1.7007e+00 4.000 1077.430 29.222 733.813\n",
      " 37 | 6.1928e+00 2.3132e+00 1.4036e-01 1.7208e+00 4.000 1115.268 28.560 727.668\n",
      " 38 | 5.9786e+00 2.1980e+00 1.4014e-01 1.7402e+00 4.000 1250.787 28.386 728.102\n",
      " 39 | 5.7730e+00 2.0903e+00 1.3994e-01 1.7590e+00 4.000 1169.296 28.509 729.521\n",
      " 40 | 5.5759e+00 1.9892e+00 1.3974e-01 1.7771e+00 4.000 1215.222 28.386 740.055\n",
      " 41 | 5.3875e+00 1.8936e+00 1.3955e-01 1.7946e+00 4.000 1242.896 28.488 731.017\n",
      " 42 | 5.2065e+00 1.8040e+00 1.3937e-01 1.8115e+00 4.000 1076.456 28.518 733.376\n",
      " 43 | 5.0329e+00 1.7197e+00 1.3920e-01 1.8279e+00 4.000 1224.368 29.536 730.798\n",
      " 44 | 4.8665e+00 1.6400e+00 1.3903e-01 1.8437e+00 4.000 1328.662 29.044 737.311\n",
      " 45 | 4.7061e+00 1.5651e+00 1.3887e-01 1.8590e+00 4.000 1191.821 28.536 736.614\n",
      " 46 | 4.5526e+00 1.4944e+00 1.3872e-01 1.8737e+00 4.000 1119.128 33.974 732.051\n",
      " 47 | 4.4050e+00 1.4278e+00 1.3857e-01 1.8880e+00 4.000 1115.861 29.817 727.836\n",
      " 48 | 4.2629e+00 1.3649e+00 1.3843e-01 1.9018e+00 4.000 1136.702 29.117 726.488\n",
      " 49 | 4.1265e+00 1.3050e+00 1.3829e-01 1.9151e+00 4.000 1147.459 28.686 738.339\n",
      " 50 | 3.9959e+00 1.2484e+00 1.3816e-01 1.9280e+00 4.000 1176.815 28.479 734.229\n",
      " 51 | 3.8700e+00 1.1949e+00 1.3803e-01 1.9404e+00 4.000 1195.154 28.775 727.682\n",
      " 52 | 3.7487e+00 1.1445e+00 1.3791e-01 1.9525e+00 4.000 1200.165 28.521 732.096\n",
      " 53 | 3.6319e+00 1.0966e+00 1.3780e-01 1.9641e+00 4.000 1063.539 28.580 733.732\n",
      " 54 | 3.5196e+00 1.0510e+00 1.3768e-01 1.9754e+00 4.000 1175.885 28.836 731.067\n",
      " 55 | 3.4109e+00 1.0078e+00 1.3758e-01 1.9863e+00 4.000 1152.223 28.427 733.178\n",
      " 56 | 3.3071e+00 9.6657e-01 1.3747e-01 1.9969e+00 4.000 1219.757 28.827 727.990\n",
      " 57 | 3.2066e+00 9.2727e-01 1.3737e-01 2.0071e+00 4.000 1059.734 28.389 729.548\n",
      " 58 | 3.1100e+00 8.8976e-01 1.3727e-01 2.0169e+00 4.000 1066.285 28.729 732.562\n",
      " 59 | 3.0169e+00 8.5412e-01 1.3718e-01 2.0265e+00 4.000 1163.827 28.904 727.027\n",
      " 60 | 2.9270e+00 8.2048e-01 1.3709e-01 2.0358e+00 4.000 1261.099 30.128 727.465\n",
      " 61 | 2.8403e+00 7.8807e-01 1.3700e-01 2.0447e+00 4.000 1114.590 28.594 731.241\n",
      " 62 | 2.7567e+00 7.5721e-01 1.3692e-01 2.0534e+00 4.000 1124.656 30.014 733.204\n",
      " 63 | 2.6759e+00 7.2820e-01 1.3684e-01 2.0618e+00 4.000 1200.191 28.812 732.824\n",
      " 64 | 2.5982e+00 7.0045e-01 1.3676e-01 2.0699e+00 4.000 1087.988 28.521 729.579\n",
      " 65 | 2.5231e+00 6.7370e-01 1.3669e-01 2.0778e+00 4.000 1247.340 28.492 726.192\n",
      " 66 | 2.4506e+00 6.4823e-01 1.3661e-01 2.0854e+00 4.000 1150.527 28.599 731.963\n",
      " 67 | 2.3807e+00 6.2387e-01 1.3654e-01 2.0928e+00 4.000 1173.885 28.468 732.608\n",
      " 68 | 2.3130e+00 6.0072e-01 1.3648e-01 2.1000e+00 4.000 1156.701 28.623 729.797\n",
      " 69 | 2.2478e+00 5.7864e-01 1.3641e-01 2.1069e+00 4.000 1118.219 29.490 730.112\n",
      " 70 | 2.1846e+00 5.5755e-01 1.3635e-01 2.1136e+00 4.000 1256.169 30.845 728.792\n",
      " 71 | 2.1235e+00 5.3731e-01 1.3629e-01 2.1201e+00 4.000 1074.946 29.145 728.292\n",
      " 72 | 2.0644e+00 5.1784e-01 1.3623e-01 2.1264e+00 4.000 1066.243 28.745 731.616\n",
      " 73 | 2.0076e+00 4.9903e-01 1.3617e-01 2.1325e+00 4.000 1184.927 28.447 730.266\n",
      " 74 | 1.9525e+00 4.8110e-01 1.3612e-01 2.1385e+00 4.000 1183.280 28.415 730.455\n",
      " 75 | 1.8990e+00 4.6403e-01 1.3606e-01 2.1442e+00 4.000 1097.134 28.400 729.045\n",
      " 76 | 1.8475e+00 4.4781e-01 1.3601e-01 2.1498e+00 4.000 1170.121 28.459 727.844\n",
      " 77 | 1.7976e+00 4.3216e-01 1.3596e-01 2.1552e+00 4.000 1117.622 32.651 736.791\n",
      " 78 | 1.7492e+00 4.1723e-01 1.3591e-01 2.1605e+00 4.000 1125.326 28.926 728.218\n",
      " 79 | 1.7026e+00 4.0282e-01 1.3587e-01 2.1655e+00 4.000 1205.046 28.608 728.541\n",
      " 80 | 1.6574e+00 3.8896e-01 1.3582e-01 2.1705e+00 4.000 1122.678 28.526 727.693\n",
      " 81 | 1.6136e+00 3.7568e-01 1.3578e-01 2.1753e+00 4.000 1119.868 29.185 729.502\n",
      " 82 | 1.5712e+00 3.6288e-01 1.3574e-01 2.1799e+00 4.000 1085.607 28.679 728.701\n",
      " 83 | 1.5301e+00 3.5060e-01 1.3569e-01 2.1844e+00 4.000 1154.178 28.464 728.060\n",
      " 84 | 1.4905e+00 3.3883e-01 1.3565e-01 2.1888e+00 4.000 1041.357 28.405 731.026\n",
      " 85 | 1.4520e+00 3.2756e-01 1.3562e-01 2.1930e+00 4.000 1150.769 28.607 730.579\n",
      " 86 | 1.4148e+00 3.1665e-01 1.3558e-01 2.1972e+00 4.000 1080.137 28.551 727.309\n",
      " 87 | 1.3787e+00 3.0620e-01 1.3554e-01 2.2012e+00 4.000 1181.929 28.488 733.267\n",
      " 88 | 1.3436e+00 2.9613e-01 1.3551e-01 2.2050e+00 4.000 1188.537 29.109 731.100\n",
      " 89 | 1.3095e+00 2.8642e-01 1.3547e-01 2.2088e+00 4.000 1095.146 28.375 732.750\n",
      " 90 | 1.2765e+00 2.7721e-01 1.3544e-01 2.2125e+00 4.000 1177.702 28.763 729.794\n",
      " 91 | 1.2446e+00 2.6821e-01 1.3541e-01 2.2160e+00 4.000 1200.879 28.883 729.155\n",
      " 92 | 1.2137e+00 2.5953e-01 1.3538e-01 2.2195e+00 4.000 1064.041 28.420 731.398\n",
      " 93 | 1.1837e+00 2.5124e-01 1.3535e-01 2.2228e+00 4.000 1135.366 29.636 731.459\n",
      " 94 | 1.1545e+00 2.4333e-01 1.3532e-01 2.2261e+00 4.000 1155.801 28.917 731.179\n",
      " 95 | 1.1260e+00 2.3569e-01 1.3529e-01 2.2293e+00 4.000 1153.136 28.618 730.243\n",
      " 96 | 1.0984e+00 2.2835e-01 1.3526e-01 2.2323e+00 4.000 1126.951 28.571 726.688\n",
      " 97 | 1.0718e+00 2.2120e-01 1.3524e-01 2.2353e+00 4.000 1062.131 28.776 731.020\n",
      " 98 | 1.0459e+00 2.1426e-01 1.3521e-01 2.2382e+00 4.000 1227.180 28.568 728.697\n",
      " 99 | 1.0207e+00 2.0765e-01 1.3518e-01 2.2411e+00 4.000 1265.151 28.659 735.967\n",
      "100 | 9.9626e-01 2.0131e-01 1.3516e-01 2.2438e+00 4.000 1254.555 28.560 727.697\n",
      "101 | 9.7253e-01 1.9518e-01 1.3514e-01 2.2465e+00 4.000 1174.127 28.436 728.919\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102 | 9.4932e-01 1.8924e-01 1.3511e-01 2.2491e+00 4.000 1089.685 28.829 731.907\n",
      "103 | 9.2686e-01 1.8353e-01 1.3509e-01 2.2516e+00 4.000 1337.966 28.756 729.763\n",
      "104 | 9.0502e-01 1.7795e-01 1.3507e-01 2.2540e+00 4.000 1613.087 30.005 726.284\n",
      "105 | 8.8382e-01 1.7259e-01 1.3505e-01 2.2564e+00 4.000 1426.513 28.827 726.443\n",
      "106 | 8.6316e-01 1.6740e-01 1.3503e-01 2.2587e+00 4.000 1245.411 28.463 727.120\n",
      "107 | 8.4320e-01 1.6240e-01 1.3501e-01 2.2610e+00 4.000 1152.875 28.448 734.520\n",
      "108 | 8.2379e-01 1.5755e-01 1.3499e-01 2.2632e+00 4.000 1147.211 29.351 729.083\n",
      "109 | 8.0488e-01 1.5295e-01 1.3497e-01 2.2653e+00 4.000 1154.143 28.842 732.116\n",
      "110 | 7.8650e-01 1.4847e-01 1.3495e-01 2.2674e+00 4.000 1097.074 28.661 727.446\n",
      "111 | 7.6861e-01 1.4411e-01 1.3493e-01 2.2694e+00 4.000 1133.496 30.930 731.023\n",
      "112 | 7.5123e-01 1.3990e-01 1.3492e-01 2.2714e+00 4.000 1073.653 34.364 731.314\n",
      "113 | 7.3430e-01 1.3584e-01 1.3490e-01 2.2733e+00 4.000 1074.207 28.438 733.423\n",
      "114 | 7.1783e-01 1.3193e-01 1.3488e-01 2.2751e+00 4.000 1072.940 28.586 746.434\n",
      "115 | 7.0181e-01 1.2817e-01 1.3487e-01 2.2769e+00 4.000 1087.642 28.576 730.937\n",
      "116 | 6.8628e-01 1.2451e-01 1.3485e-01 2.2787e+00 4.000 1150.948 30.776 730.351\n",
      "117 | 6.7110e-01 1.2095e-01 1.3484e-01 2.2804e+00 4.000 1199.801 28.755 729.100\n",
      "118 | 6.5631e-01 1.1753e-01 1.3482e-01 2.2821e+00 4.000 1219.114 28.525 736.507\n",
      "119 | 6.4187e-01 1.1424e-01 1.3481e-01 2.2837e+00 4.000 1130.319 30.722 733.837\n",
      "120 | 6.2780e-01 1.1105e-01 1.3479e-01 2.2853e+00 4.000 1056.474 28.446 732.883\n",
      "121 | 6.1420e-01 1.0792e-01 1.3478e-01 2.2868e+00 4.000 1199.722 28.325 733.500\n",
      "122 | 6.0096e-01 1.0489e-01 1.3477e-01 2.2883e+00 4.000 1241.419 28.691 729.556\n",
      "123 | 5.8812e-01 1.0197e-01 1.3475e-01 2.2898e+00 4.000 1085.132 28.412 729.339\n",
      "124 | 5.7552e-01 9.9154e-02 1.3474e-01 2.2912e+00 4.000 1235.297 28.455 737.103\n",
      "125 | 5.6325e-01 9.6449e-02 1.3473e-01 2.2926e+00 4.000 1327.332 28.629 733.218\n",
      "126 | 5.5123e-01 9.3836e-02 1.3472e-01 2.2939e+00 4.000 1208.743 28.672 731.539\n",
      "127 | 5.3966e-01 9.1250e-02 1.3470e-01 2.2953e+00 4.000 1113.535 29.980 732.020\n",
      "128 | 5.2826e-01 8.8787e-02 1.3469e-01 2.2965e+00 4.000 2783.878 29.452 1416.994\n",
      "129 | 5.1721e-01 8.6396e-02 1.3468e-01 2.2978e+00 4.000 2733.280 29.361 756.694\n",
      "130 | 5.0639e-01 8.4070e-02 1.3467e-01 2.2990e+00 4.000 1699.126 29.607 736.650\n",
      "131 | 4.9581e-01 8.1847e-02 1.3466e-01 2.3002e+00 4.000 1365.152 29.752 735.240\n",
      "132 | 4.8561e-01 7.9620e-02 1.3465e-01 2.3013e+00 4.000 1174.628 28.812 732.566\n",
      "133 | 4.7559e-01 7.7460e-02 1.3464e-01 2.3025e+00 4.000 1178.260 28.590 731.501\n",
      "134 | 4.6589e-01 7.5416e-02 1.3463e-01 2.3035e+00 4.000 1151.929 28.449 739.652\n",
      "135 | 4.5636e-01 7.3431e-02 1.3462e-01 2.3046e+00 4.000 1165.799 28.570 733.494\n",
      "136 | 4.4701e-01 7.1551e-02 1.3461e-01 2.3057e+00 4.000 1197.483 28.772 733.929\n",
      "137 | 4.3797e-01 6.9713e-02 1.3460e-01 2.3067e+00 4.000 1237.215 28.823 732.591\n",
      "138 | 4.2920e-01 6.7879e-02 1.3459e-01 2.3077e+00 4.000 1144.430 29.183 744.621\n",
      "139 | 4.2055e-01 6.6060e-02 1.3458e-01 2.3086e+00 4.000 1267.039 28.703 733.137\n",
      "140 | 4.1212e-01 6.4365e-02 1.3458e-01 2.3096e+00 4.000 1130.889 28.592 729.479\n",
      "141 | 4.0392e-01 6.2716e-02 1.3457e-01 2.3105e+00 4.000 1081.346 28.448 728.747\n",
      "142 | 3.9587e-01 6.1133e-02 1.3456e-01 2.3114e+00 4.000 1175.550 28.874 728.571\n",
      "143 | 3.8813e-01 5.9545e-02 1.3455e-01 2.3122e+00 4.000 1114.013 28.499 725.880\n",
      "144 | 3.8053e-01 5.8033e-02 1.3454e-01 2.3131e+00 4.000 1173.883 28.699 732.874\n",
      "145 | 3.7314e-01 5.6563e-02 1.3454e-01 2.3139e+00 4.000 1220.347 28.591 731.122\n",
      "146 | 3.6595e-01 5.5127e-02 1.3453e-01 2.3147e+00 4.000 1151.745 28.851 725.627\n",
      "147 | 3.5893e-01 5.3732e-02 1.3452e-01 2.3155e+00 4.000 1151.536 28.380 728.027\n",
      "148 | 3.5203e-01 5.2378e-02 1.3452e-01 2.3163e+00 4.000 1161.040 28.925 727.347\n",
      "149 | 3.4523e-01 5.1094e-02 1.3451e-01 2.3170e+00 4.000 1146.725 30.453 725.822\n",
      "150 | 3.3873e-01 4.9825e-02 1.3450e-01 2.3178e+00 4.000 1158.937 28.542 721.223\n",
      "151 | 3.3237e-01 4.8560e-02 1.3450e-01 2.3185e+00 4.000 597.048 28.542 683.448\n",
      "152 | 3.2611e-01 4.7378e-02 1.3449e-01 2.3192e+00 4.000 549.566 28.849 677.676\n",
      "153 | 3.1999e-01 4.6230e-02 1.3448e-01 2.3199e+00 4.000 570.819 28.579 675.763\n",
      "154 | 3.1398e-01 4.5099e-02 1.3448e-01 2.3205e+00 4.000 634.347 28.507 680.059\n",
      "155 | 3.0812e-01 4.3990e-02 1.3447e-01 2.3212e+00 4.000 561.655 28.712 701.247\n",
      "156 | 3.0240e-01 4.2927e-02 1.3447e-01 2.3218e+00 4.000 606.589 28.841 682.265\n",
      "157 | 2.9682e-01 4.1913e-02 1.3446e-01 2.3224e+00 4.000 555.457 28.599 668.653\n",
      "158 | 2.9138e-01 4.0894e-02 1.3446e-01 2.3230e+00 4.000 549.878 31.058 663.423\n",
      "159 | 2.8596e-01 3.9902e-02 1.3445e-01 2.3236e+00 4.000 568.470 29.409 669.578\n",
      "160 | 2.8070e-01 3.8964e-02 1.3444e-01 2.3242e+00 4.000 541.251 28.582 658.824\n",
      "161 | 2.7558e-01 3.8040e-02 1.3444e-01 2.3247e+00 4.000 642.305 28.529 656.201\n",
      "162 | 2.7054e-01 3.7149e-02 1.3443e-01 2.3253e+00 4.000 531.094 28.644 651.896\n",
      "163 | 2.6557e-01 3.6286e-02 1.3443e-01 2.3258e+00 4.000 539.531 28.567 662.245\n",
      "164 | 2.6073e-01 3.5469e-02 1.3442e-01 2.3263e+00 4.000 551.834 29.104 649.392\n",
      "165 | 2.5603e-01 3.4653e-02 1.3442e-01 2.3269e+00 4.000 548.728 29.284 644.550\n",
      "166 | 2.5146e-01 3.3829e-02 1.3442e-01 2.3274e+00 4.000 541.885 30.399 648.520\n",
      "167 | 2.4698e-01 3.3046e-02 1.3441e-01 2.3278e+00 4.000 529.598 28.876 640.618\n",
      "168 | 2.4260e-01 3.2268e-02 1.3441e-01 2.3283e+00 4.000 516.599 28.842 638.600\n",
      "169 | 2.3829e-01 3.1531e-02 1.3440e-01 2.3288e+00 4.000 542.464 28.477 638.571\n",
      "170 | 2.3403e-01 3.0816e-02 1.3440e-01 2.3292e+00 4.000 516.764 28.564 631.348\n",
      "171 | 2.2989e-01 3.0131e-02 1.3439e-01 2.3297e+00 4.000 537.068 28.430 629.292\n",
      "172 | 2.2587e-01 2.9453e-02 1.3439e-01 2.3301e+00 4.000 523.217 29.015 626.976\n",
      "173 | 2.2195e-01 2.8779e-02 1.3439e-01 2.3305e+00 4.000 513.362 28.542 623.240\n",
      "174 | 2.1816e-01 2.8096e-02 1.3438e-01 2.3309e+00 4.000 580.840 28.518 619.810\n",
      "175 | 2.1445e-01 2.7423e-02 1.3438e-01 2.3313e+00 4.000 608.359 28.869 626.200\n",
      "176 | 2.1077e-01 2.6831e-02 1.3437e-01 2.3317e+00 4.000 506.302 29.020 615.289\n",
      "177 | 2.0717e-01 2.6237e-02 1.3437e-01 2.3321e+00 4.000 526.576 28.445 611.276\n",
      "178 | 2.0367e-01 2.5660e-02 1.3437e-01 2.3325e+00 4.000 527.839 28.592 609.906\n",
      "179 | 2.0027e-01 2.5073e-02 1.3436e-01 2.3329e+00 4.000 531.558 28.402 608.574\n",
      "180 | 1.9687e-01 2.4522e-02 1.3436e-01 2.3332e+00 4.000 519.402 29.194 611.975\n",
      "181 | 1.9358e-01 2.3989e-02 1.3436e-01 2.3336e+00 4.000 520.041 28.664 601.770\n",
      "182 | 1.9037e-01 2.3442e-02 1.3435e-01 2.3339e+00 4.000 524.527 30.876 600.694\n",
      "183 | 1.8721e-01 2.2943e-02 1.3435e-01 2.3343e+00 4.000 547.988 29.127 608.057\n",
      "184 | 1.8414e-01 2.2430e-02 1.3435e-01 2.3346e+00 4.000 521.424 28.626 598.682\n",
      "185 | 1.8109e-01 2.1945e-02 1.3435e-01 2.3349e+00 4.000 511.282 35.469 588.751\n",
      "186 | 1.7805e-01 2.1506e-02 1.3434e-01 2.3352e+00 4.000 524.394 29.092 587.907\n",
      "187 | 1.7509e-01 2.1075e-02 1.3434e-01 2.3355e+00 4.000 533.851 29.552 592.956\n",
      "188 | 1.7226e-01 2.0607e-02 1.3434e-01 2.3358e+00 4.000 517.603 28.517 599.060\n",
      "189 | 1.6946e-01 2.0160e-02 1.3433e-01 2.3361e+00 4.000 513.525 28.432 588.697\n",
      "190 | 1.6664e-01 1.9770e-02 1.3433e-01 2.3364e+00 4.000 519.527 28.564 585.098\n",
      "191 | 1.6387e-01 1.9362e-02 1.3433e-01 2.3367e+00 4.000 520.666 29.646 582.640\n",
      "192 | 1.6124e-01 1.8970e-02 1.3433e-01 2.3370e+00 4.000 511.760 28.482 577.125\n",
      "193 | 1.5869e-01 1.8525e-02 1.3432e-01 2.3372e+00 4.000 523.926 28.828 572.770\n",
      "194 | 1.5618e-01 1.8116e-02 1.3432e-01 2.3375e+00 4.000 525.468 29.425 568.984\n",
      "195 | 1.5366e-01 1.7745e-02 1.3432e-01 2.3378e+00 4.000 525.036 28.391 565.826\n",
      "196 | 1.5127e-01 1.7380e-02 1.3432e-01 2.3380e+00 4.000 516.473 29.101 567.802\n",
      "197 | 1.4890e-01 1.7019e-02 1.3431e-01 2.3383e+00 4.000 533.229 28.431 574.456\n",
      "198 | 1.4652e-01 1.6671e-02 1.3431e-01 2.3385e+00 4.000 531.840 29.670 563.235\n",
      "199 | 1.4418e-01 1.6325e-02 1.3431e-01 2.3387e+00 4.000 531.751 28.416 560.257\n",
      "200 | 1.4190e-01 1.6005e-02 1.3431e-01 2.3390e+00 4.000 518.663 28.520 558.794\n",
      "201 | 1.3971e-01 1.5674e-02 1.3430e-01 2.3392e+00 4.000 550.097 28.985 555.973\n",
      "202 | 1.3752e-01 1.5367e-02 1.3430e-01 2.3394e+00 4.000 509.048 28.300 552.702\n",
      "203 | 1.3536e-01 1.5047e-02 1.3430e-01 2.3396e+00 4.000 516.679 28.636 554.039\n",
      "204 | 1.3331e-01 1.4774e-02 1.3430e-01 2.3398e+00 4.000 518.878 28.517 549.418\n",
      "Terminated (optimal) in 204 iterations.\n",
      "run time: 3.5725e+02 seconds\n",
      "RESULTS OF STRATIFIED MODEL:\n",
      "\t\t Info:  {'time': 357.2522157090716, 'iterations': 204, 'optimal': True}\n",
      "\t\t Test ANLL:  0.06896136190892214\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Stratified model\"\"\"\n",
    "kwargs = dict(verbose=True, abs_tol=1e-4, maxiter=500)\n",
    "\n",
    "min_anll = np.inf\n",
    "argmin_gamma = (np.inf, np.inf)\n",
    "weights_gam1 = np.logspace(np.log10(1e-3), np.log10(1e3), 50)\n",
    "weights_gam2 = np.logspace(np.log10(1e-3), np.log10(1e0), 50)\n",
    "range_weights = np.logspace(np.log10(1e-2), np.log10(1e3), 100)\n",
    "azimuth_weights = np.logspace(np.log10(1e-2), np.log10(1e3), 100)\n",
    "doppler_weights = np.logspace(np.log10(1e-2), np.log10(1e3), 100)\n",
    "\n",
    "gamma = (2.68, 0.66)\n",
    "wt_range, wt_azimuth, wt_doppler = (10.52, 34.30, 86.97)\n",
    "\n",
    "print(\"\\t Stratified model, local weights = \", gamma)\n",
    "print(\"\\t (r,a,d) weights = \", (wt_range, wt_azimuth, wt_doppler))\n",
    "\n",
    "strat_models.set_edge_weight(G_range, wt_range)\n",
    "strat_models.set_edge_weight(G_azimuth, wt_azimuth)\n",
    "strat_models.set_edge_weight(G_doppler, wt_doppler)\n",
    "G = strat_models.cartesian_product([G_range, G_azimuth, G_doppler])\n",
    "\n",
    "loss = covariance_max_likelihood_loss()\n",
    "reg = trace_offdiagL1Norm(lambd=gamma)\n",
    "\n",
    "bm = strat_models.BaseModel(loss=loss, reg=reg)\n",
    "sm = strat_models.StratifiedModel(bm, graph=G)\n",
    "\n",
    "info = sm.fit(data_train, **kwargs)\n",
    "\n",
    "anll = sm.anll(data_test)/sum(NUM_SAMPLES_TEST)\n",
    "print(\"RESULTS OF STRATIFIED MODEL:\")\n",
    "print(\"\\t\\t Info: \", info)\n",
    "print(\"\\t\\t Test ANLL: \", anll)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stratified 1.6203289616587575\n",
      "Common 2.018051183819809\n"
     ]
    }
   ],
   "source": [
    "for model, model_type in zip([sm], [\"Stratified\"]):\n",
    "    divergences = []\n",
    "    for node in sm.G.nodes():\n",
    "        divergences += [np.trace(S_trues[node]@model.G._node[node][\"theta\"]) - np.linalg.slogdet(model.G._node[node][\"theta\"])[1]]\n",
    "    \n",
    "    avg_divergence = np.mean(divergences)/n\n",
    "    print(model_type, avg_divergence)\n",
    "\n",
    "divergences = []\n",
    "for node in sm.G.nodes():\n",
    "    divergences += [np.trace(S_trues[node]@common.G._node[0][\"theta\"]) - np.linalg.slogdet(common.G._node[0][\"theta\"])[1]]\n",
    "avg_divergence = np.mean(divergences)/n\n",
    "print(\"Common\", avg_divergence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[35000.0, 36666.666666666664, 38333.333333333336, 40000.0, 41666.666666666664, 43333.333333333336, 45000.0, 46666.66666666667, 48333.333333333336, 50000.0]\n",
      "[87.0, 107.0, 127.0, 147.0, 167.0, 187.0, 207.0, 227.0, 247.0, 267.0]\n",
      "[-992.0, -771.5555555555555, -551.1111111111111, -330.66666666666663, -110.22222222222217, 110.22222222222217, 330.66666666666674, 551.1111111111113, 771.5555555555557, 992.0]\n"
     ]
    }
   ],
   "source": [
    "print(ranges)\n",
    "print(azimuths)\n",
    "print(dopplers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is the radar experiment\n",
    "#n == 30, so that means that JP = n.\n",
    "#J = number of radar elements\n",
    "#P = number of pulses\n",
    "\n",
    "J = 5\n",
    "P = 3\n",
    "\n",
    "fc = 1240e6 # carrier frequency, in hz\n",
    "fR = 1984 # pulse repetition frequency, in hz\n",
    "\n",
    "zs_t = []\n",
    "for ft in dopplers:\n",
    "    zs_t += [np.exp(1j*2*np.pi*ft/fR)]\n",
    "\n",
    "zs_s = []\n",
    "for phi_t in azimuths:\n",
    "    zs_s += [np.exp(1j*2*np.pi*np.sin(phi_t))]\n",
    "    \n",
    "ss_s = [np.array([z**i for i in range(J)]) for z in zs_s]\n",
    "ss_t = [np.array([z**i for i in range(P)]) for z in zs_t]\n",
    "\n",
    "Ss = dict()\n",
    "for ran in ranges:\n",
    "    for (azi, ss) in zip(azimuths,ss_s):\n",
    "        for (dop, st) in zip(dopplers, ss_t):\n",
    "            s = np.kron(st, ss)\n",
    "            Ss[ran, azi, dop] = np.concatenate([np.real(s), np.imag(s)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathantuck/opt/anaconda3/envs/research/lib/python3.6/site-packages/ipykernel_launcher.py:11: RuntimeWarning: covariance is not positive-semidefinite.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "#randomly pick a range/azi/dop combo and associate it with\n",
    "np.random.seed(0)\n",
    "\n",
    "num_per_node = 1\n",
    "alpha=1.5\n",
    "\n",
    "Ys = dict()\n",
    "for node in S_trues.keys():\n",
    "    ys_node = []\n",
    "    for _ in range(num_per_node):\n",
    "        interference_noise = np.random.multivariate_normal(np.zeros(n), np.real(S_trues[node]))\n",
    "        if np.random.rand() <= 0.5:\n",
    "            ys_node += [(interference_noise + alpha*Ss[node], \"TARGET\")] #corresponds to Ss[azi, dop]\n",
    "        else:\n",
    "            ys_node += [(interference_noise, \"NOISE\")]\n",
    "    Ys[node] = ys_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMMON AUC-ROC: 0.844624\n",
      "COMMON AUC-ROC: 0.9500960000000002\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "common_ROC = []\n",
    "strat_ROC = []\n",
    "\n",
    "theta_common = common.G._node[0][\"theta\"]\n",
    "\n",
    "for thresh in np.logspace(-4,5,1000):\n",
    "    tp_common = 0\n",
    "    fp_common = 0\n",
    "    \n",
    "    tp_strat = 0\n",
    "    fp_strat = 0\n",
    "    \n",
    "    tot_pos = 0\n",
    "    tot_neg = 0\n",
    "    for node in list(sm.G.nodes()):\n",
    "        s = Ss[node]\n",
    "        theta_z = sm.G._node[node][\"theta\"]\n",
    "        \n",
    "        for (y, istar) in Ys[node]:\n",
    "            if istar == \"TARGET\":\n",
    "                tot_pos += 1\n",
    "            else:\n",
    "                tot_neg += 1\n",
    "            #common        \n",
    "            stat_common = abs(s.T@theta_common@y)**2/(s.T@theta_common@s)\n",
    "            if stat_common > thresh and istar == \"TARGET\":\n",
    "                tp_common += 1\n",
    "            if stat_common > thresh and istar == \"NOISE\":\n",
    "                fp_common += 1\n",
    "        \n",
    "            #strat\n",
    "            stat_sm = abs(s.T@theta_z@y)**2/(s.T@theta_z@s)\n",
    "            if stat_sm > thresh and istar == \"TARGET\":\n",
    "                tp_strat += 1\n",
    "            if stat_sm > thresh and istar == \"NOISE\":\n",
    "                fp_strat += 1\n",
    "                \n",
    "    common_ROC += [(fp_common/tot_neg, tp_common/tot_pos)]\n",
    "    strat_ROC += [(fp_strat/tot_neg, tp_strat/tot_pos)]\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(5,5))\n",
    "\n",
    "ax.plot([c[0] for c in common_ROC], [c[1] for c in common_ROC], label=\"Common model\", color=\"blue\")\n",
    "ax.plot([c[0] for c in strat_ROC], [c[1] for c in strat_ROC], label=\"Stratified model\", color=\"black\")\n",
    "ax.set_xlabel(\"False positive rate\", fontsize=\"large\")\n",
    "ax.set_ylabel(\"True positive rate\", fontsize=\"large\")\n",
    "ax.set_aspect(1.0)\n",
    "ax.legend()\n",
    "\n",
    "AUC_ROC_common = auc([c[0] for c in common_ROC], [c[1] for c in common_ROC])\n",
    "AUC_ROC_strat = auc([c[0] for c in strat_ROC], [c[1] for c in strat_ROC])\n",
    "print(\"COMMON AUC-ROC:\", AUC_ROC_common)\n",
    "print(\"COMMON AUC-ROC:\", AUC_ROC_strat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research",
   "language": "python",
   "name": "research"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
